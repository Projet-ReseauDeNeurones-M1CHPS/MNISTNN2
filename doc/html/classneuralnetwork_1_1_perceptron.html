<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>MNISTNN: neuralnetwork::Perceptron&lt; DEPTH &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">MNISTNN
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>neuralnetwork</b></li><li class="navelem"><a class="el" href="classneuralnetwork_1_1_perceptron.html">Perceptron</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classneuralnetwork_1_1_perceptron-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">neuralnetwork::Perceptron&lt; DEPTH &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Classe <a class="el" href="classneuralnetwork_1_1_perceptron.html" title="Classe Perceptron. ">Perceptron</a>.  
 <a href="classneuralnetwork_1_1_perceptron.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_perceptron_8hpp_source.html">Perceptron.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a611ca300c9ad690d3d9496ed8f6634af"><td class="memTemplParams" colspan="2">template&lt;typename ... Args&gt; </td></tr>
<tr class="memitem:a611ca300c9ad690d3d9496ed8f6634af"><td class="memTemplItemLeft" align="right" valign="top">&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classneuralnetwork_1_1_perceptron.html#a611ca300c9ad690d3d9496ed8f6634af">Perceptron</a> (double min, double max, Args... args)</td></tr>
<tr class="memdesc:a611ca300c9ad690d3d9496ed8f6634af"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructeur, les poids du reseau sont initialises entre deux bornes de maniere aleatoire, on definit egalement la taille des couches et leurs fonctions d'activation.  <a href="#a611ca300c9ad690d3d9496ed8f6634af">More...</a><br /></td></tr>
<tr class="separator:a611ca300c9ad690d3d9496ed8f6634af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82ed55bb881ead0fd7bb8b37a870fd98"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnetwork_1_1_perceptron.html#a82ed55bb881ead0fd7bb8b37a870fd98">initWeights</a> (double min, double max)</td></tr>
<tr class="memdesc:a82ed55bb881ead0fd7bb8b37a870fd98"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initialisation aleatoire des poids du reseau entre deux bornes.  <a href="#a82ed55bb881ead0fd7bb8b37a870fd98">More...</a><br /></td></tr>
<tr class="separator:a82ed55bb881ead0fd7bb8b37a870fd98"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6930cbdbb12382ffe13a5201d8ef47a8"><td class="memItemLeft" align="right" valign="top">double &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnetwork_1_1_perceptron.html#a6930cbdbb12382ffe13a5201d8ef47a8">weight</a> (std::size_t couch, std::size_t neuron, std::size_t previous)</td></tr>
<tr class="memdesc:a6930cbdbb12382ffe13a5201d8ef47a8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Accesseur des poids du reseau.  <a href="#a6930cbdbb12382ffe13a5201d8ef47a8">More...</a><br /></td></tr>
<tr class="separator:a6930cbdbb12382ffe13a5201d8ef47a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e4e8b2536a300feb5050478bd54e0ab"><td class="memItemLeft" align="right" valign="top">std::size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnetwork_1_1_perceptron.html#a9e4e8b2536a300feb5050478bd54e0ab">weights_count</a> (std::size_t couch)</td></tr>
<tr class="memdesc:a9e4e8b2536a300feb5050478bd54e0ab"><td class="mdescLeft">&#160;</td><td class="mdescRight">Nombre de poids de chaque neurone d'une couche.  <a href="#a9e4e8b2536a300feb5050478bd54e0ab">More...</a><br /></td></tr>
<tr class="separator:a9e4e8b2536a300feb5050478bd54e0ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a967eda62d33f3ac45cff0e6be3e6630a"><td class="memItemLeft" align="right" valign="top">std::size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnetwork_1_1_perceptron.html#a967eda62d33f3ac45cff0e6be3e6630a">depth</a> ()</td></tr>
<tr class="memdesc:a967eda62d33f3ac45cff0e6be3e6630a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Profondeur du reseau.  <a href="#a967eda62d33f3ac45cff0e6be3e6630a">More...</a><br /></td></tr>
<tr class="separator:a967eda62d33f3ac45cff0e6be3e6630a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a781b53edd909baab32eb6f6d9a3921d6"><td class="memItemLeft" align="right" valign="top">std::size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnetwork_1_1_perceptron.html#a781b53edd909baab32eb6f6d9a3921d6">couch_size</a> (std::size_t couch)</td></tr>
<tr class="memdesc:a781b53edd909baab32eb6f6d9a3921d6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Nombre de neurones d'une couche donnee.  <a href="#a781b53edd909baab32eb6f6d9a3921d6">More...</a><br /></td></tr>
<tr class="separator:a781b53edd909baab32eb6f6d9a3921d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a41fec540bd2a224e43ab156623fce304"><td class="memItemLeft" align="right" valign="top"><a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; double, neuralnetwork::InOutType::DYNAMIC &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnetwork_1_1_perceptron.html#a41fec540bd2a224e43ab156623fce304">agreg</a> (std::size_t couch)</td></tr>
<tr class="memdesc:a41fec540bd2a224e43ab156623fce304"><td class="mdescLeft">&#160;</td><td class="mdescRight">Les dernieres agregations enregistrees pour une couche donnee (methode principalement utile au debugage)  <a href="#a41fec540bd2a224e43ab156623fce304">More...</a><br /></td></tr>
<tr class="separator:a41fec540bd2a224e43ab156623fce304"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaccd517b8c133cd12b19ec22f04a299e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; double, neuralnetwork::InOutType::DYNAMIC &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnetwork_1_1_perceptron.html#aaccd517b8c133cd12b19ec22f04a299e">activation</a> (std::size_t couch)</td></tr>
<tr class="memdesc:aaccd517b8c133cd12b19ec22f04a299e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Les dernieres activations enregistrees pour une couche donnee (methode principalement utile au debugage)  <a href="#aaccd517b8c133cd12b19ec22f04a299e">More...</a><br /></td></tr>
<tr class="separator:aaccd517b8c133cd12b19ec22f04a299e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab05c12459b4ee03a75cc241b59aa0481"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnetwork_1_1_perceptron.html#ab05c12459b4ee03a75cc241b59aa0481">printMatrixCouch</a> (std::ostream &amp;out, std::size_t i)</td></tr>
<tr class="memdesc:ab05c12459b4ee03a75cc241b59aa0481"><td class="mdescLeft">&#160;</td><td class="mdescRight">Ecrit la matrice des poids d'une couche, une ligne correspond a un neurone, les poids sont dans l'odre des entrees provenant de la couche precedente et les agregations et activations de cette couche (methode principalement utile au debugage)  <a href="#ab05c12459b4ee03a75cc241b59aa0481">More...</a><br /></td></tr>
<tr class="separator:ab05c12459b4ee03a75cc241b59aa0481"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a83e9fbb5f68a8281fe29c51cc538e44c"><td class="memTemplParams" colspan="2">template&lt;typename tin , int INPUT_SIZE, typename tout , int OUTPUT_SIZE&gt; </td></tr>
<tr class="memitem:a83e9fbb5f68a8281fe29c51cc538e44c"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classneuralnetwork_1_1_perceptron.html#a83e9fbb5f68a8281fe29c51cc538e44c">feedForward</a> (<a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; tin, INPUT_SIZE &gt; &amp;in, <a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; tout, OUTPUT_SIZE &gt; &amp;out, bool saveAgreg, bool saveActivation)</td></tr>
<tr class="memdesc:a83e9fbb5f68a8281fe29c51cc538e44c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Evalue une entree avec le reseau.  <a href="#a83e9fbb5f68a8281fe29c51cc538e44c">More...</a><br /></td></tr>
<tr class="separator:a83e9fbb5f68a8281fe29c51cc538e44c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac65162cfaacf1d9e9493a0f71efe84f5"><td class="memTemplParams" colspan="2">template&lt;typename t , int INPUT_SIZE&gt; </td></tr>
<tr class="memitem:ac65162cfaacf1d9e9493a0f71efe84f5"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classneuralnetwork_1_1_perceptron.html#ac65162cfaacf1d9e9493a0f71efe84f5">applyActivation</a> (<a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; t, INPUT_SIZE &gt; &amp;in, std::size_t fi)</td></tr>
<tr class="memdesc:ac65162cfaacf1d9e9493a0f71efe84f5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Applique la fonction d'activation sur l'agregation calulee d'une couche.  <a href="#ac65162cfaacf1d9e9493a0f71efe84f5">More...</a><br /></td></tr>
<tr class="separator:ac65162cfaacf1d9e9493a0f71efe84f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3aef48d797fceda980d1cbf63ba62eff"><td class="memTemplParams" colspan="2">template&lt;typename tin , int INPUT_SIZE, typename tout , int OUTPUT_SIZE&gt; </td></tr>
<tr class="memitem:a3aef48d797fceda980d1cbf63ba62eff"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classneuralnetwork_1_1_perceptron.html#a3aef48d797fceda980d1cbf63ba62eff">backpropagation</a> (<a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; tin, INPUT_SIZE &gt; *ins, <a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; tout, OUTPUT_SIZE &gt; *outs, std::size_t n, double step)</td></tr>
<tr class="memdesc:a3aef48d797fceda980d1cbf63ba62eff"><td class="mdescLeft">&#160;</td><td class="mdescRight">Applique l'algorithme de retropropagation du gradient avec un jeu d'exemples afin d'entrainer le reseau.  <a href="#a3aef48d797fceda980d1cbf63ba62eff">More...</a><br /></td></tr>
<tr class="separator:a3aef48d797fceda980d1cbf63ba62eff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a220623af970ea20a00bc2d9096946cbc"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnetwork_1_1_perceptron.html#a220623af970ea20a00bc2d9096946cbc">initGraph</a> (double step, int nb_threads)</td></tr>
<tr class="memdesc:a220623af970ea20a00bc2d9096946cbc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initailise les graphes TBB pour le feed forward et la retropropagation.  <a href="#a220623af970ea20a00bc2d9096946cbc">More...</a><br /></td></tr>
<tr class="separator:a220623af970ea20a00bc2d9096946cbc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a759d5647ad309215f083d5c8519838ee"><td class="memTemplParams" colspan="2">template&lt;typename tin , int INPUT_SIZE, typename tout , int OUTPUT_SIZE&gt; </td></tr>
<tr class="memitem:a759d5647ad309215f083d5c8519838ee"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classneuralnetwork_1_1_perceptron.html#a759d5647ad309215f083d5c8519838ee">parallel_feedForward</a> (<a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; tin, INPUT_SIZE &gt; &amp;in, <a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; tout, OUTPUT_SIZE &gt; &amp;out)</td></tr>
<tr class="memdesc:a759d5647ad309215f083d5c8519838ee"><td class="mdescLeft">&#160;</td><td class="mdescRight">Evalue une entree avec le reseau avec TBB.  <a href="#a759d5647ad309215f083d5c8519838ee">More...</a><br /></td></tr>
<tr class="separator:a759d5647ad309215f083d5c8519838ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f2a106043e5febb19e0d18a94e32dcc"><td class="memTemplParams" colspan="2">template&lt;typename tin , int INPUT_SIZE, typename tout , int OUTPUT_SIZE&gt; </td></tr>
<tr class="memitem:a0f2a106043e5febb19e0d18a94e32dcc"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classneuralnetwork_1_1_perceptron.html#a0f2a106043e5febb19e0d18a94e32dcc">parallel_backpropagation</a> (<a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; tin, INPUT_SIZE &gt; *ins, <a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; tout, OUTPUT_SIZE &gt; *outs, std::size_t n, double step)</td></tr>
<tr class="memdesc:a0f2a106043e5febb19e0d18a94e32dcc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Applique l'algorithme de retropropagation du gradient avec un jeu d'exemples afin d'entrainer le reseau avec TBB.  <a href="#a0f2a106043e5febb19e0d18a94e32dcc">More...</a><br /></td></tr>
<tr class="separator:a0f2a106043e5febb19e0d18a94e32dcc"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;std::size_t DEPTH&gt;<br />
class neuralnetwork::Perceptron&lt; DEPTH &gt;</h3>

<p>Classe <a class="el" href="classneuralnetwork_1_1_perceptron.html" title="Classe Perceptron. ">Perceptron</a>. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">DEPTH</td><td>nombres de couches du perceptron sans compter la couche d'entrée </td></tr>
  </table>
  </dd>
</dl>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a611ca300c9ad690d3d9496ed8f6634af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a611ca300c9ad690d3d9496ed8f6634af">&#9670;&nbsp;</a></span>Perceptron()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;std::size_t DEPTH&gt; </div>
<div class="memtemplate">
template&lt;typename ... Args&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classneuralnetwork_1_1_perceptron.html">neuralnetwork::Perceptron</a>&lt; DEPTH &gt;::<a class="el" href="classneuralnetwork_1_1_perceptron.html">Perceptron</a> </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>min</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>max</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Args...&#160;</td>
          <td class="paramname"><em>args</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructeur, les poids du reseau sont initialises entre deux bornes de maniere aleatoire, on definit egalement la taille des couches et leurs fonctions d'activation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">min</td><td>Valeur minimal d'un poids du reseau </td></tr>
    <tr><td class="paramname">max</td><td>Valeur maximal d'un poids du reseau </td></tr>
    <tr><td class="paramname">args</td><td>Trois arguments pour definie une couche, le premier est le nombre de neurone de la couche, le deuxieme est est la fonction d'activation, le troisieme est la derivee de la fonction d'activation. Les trois premiers arguments definissent la premiere couche cachee, les trois suivants la deuxieme couche cachee, etc... la fonction d'activation et sa derivee doivent etre des pointeurs sur fonction qui prennent un double et retourne un double </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="aaccd517b8c133cd12b19ec22f04a299e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaccd517b8c133cd12b19ec22f04a299e">&#9670;&nbsp;</a></span>activation()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;std::size_t DEPTH&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">Eigen::Matrix&lt; double, Eigen::Dynamic, 1 &gt; <a class="el" href="classneuralnetwork_1_1_perceptron.html">neuralnetwork::Perceptron</a>&lt; DEPTH &gt;::activation </td>
          <td>(</td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>couch</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Les dernieres activations enregistrees pour une couche donnee (methode principalement utile au debugage) </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">couch</td><td>La couche en question </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>une entree-sortie de neurones qui comporte toutes les dernieres activations enregistrees de la couche en question </dd></dl>

</div>
</div>
<a id="a41fec540bd2a224e43ab156623fce304"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a41fec540bd2a224e43ab156623fce304">&#9670;&nbsp;</a></span>agreg()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;std::size_t DEPTH&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">Eigen::Matrix&lt; double, Eigen::Dynamic, 1 &gt; <a class="el" href="classneuralnetwork_1_1_perceptron.html">neuralnetwork::Perceptron</a>&lt; DEPTH &gt;::agreg </td>
          <td>(</td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>couch</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Les dernieres agregations enregistrees pour une couche donnee (methode principalement utile au debugage) </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">couch</td><td>La couche en question </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>une entree-sortie de neurones qui comporte toutes les dernieres agregation enregistrees de la couche en question </dd></dl>

</div>
</div>
<a id="ac65162cfaacf1d9e9493a0f71efe84f5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac65162cfaacf1d9e9493a0f71efe84f5">&#9670;&nbsp;</a></span>applyActivation()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;std::size_t DEPTH&gt; </div>
<div class="memtemplate">
template&lt;typename t , int INPUT_SIZE&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classneuralnetwork_1_1_perceptron.html">neuralnetwork::Perceptron</a>&lt; DEPTH &gt;::applyActivation </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; t, INPUT_SIZE &gt; &amp;&#160;</td>
          <td class="paramname"><em>in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>fi</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Applique la fonction d'activation sur l'agregation calulee d'une couche. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">in</td><td>L'aggregation calculee de la couche fi </td></tr>
    <tr><td class="paramname">fi</td><td>La couche en question </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Rien </dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">tin</td><td>type de l'agreation (a priori un double) </td></tr>
    <tr><td class="paramname">INPUT_SIZE</td><td>taille de la couche </td></tr>
    <tr><td class="paramname">tout</td><td>type de l'activation (a priori un double) </td></tr>
    <tr><td class="paramname">OUTPUT_SIZE</td><td>taille de la couche </td></tr>
  </table>
  </dd>
</dl>
<dl class="todo"><dt><b><a class="el" href="todo.html#_todo000001">Todo:</a></b></dt><dd>possibilite de se passer de in si feedForward enregistre systematiquement l'agregation </dd></dl>

</div>
</div>
<a id="a3aef48d797fceda980d1cbf63ba62eff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3aef48d797fceda980d1cbf63ba62eff">&#9670;&nbsp;</a></span>backpropagation()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;std::size_t DEPTH&gt; </div>
<div class="memtemplate">
template&lt;typename tin , int INPUT_SIZE, typename tout , int OUTPUT_SIZE&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classneuralnetwork_1_1_perceptron.html">neuralnetwork::Perceptron</a>&lt; DEPTH &gt;::backpropagation </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; tin, INPUT_SIZE &gt; *&#160;</td>
          <td class="paramname"><em>ins</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; tout, OUTPUT_SIZE &gt; *&#160;</td>
          <td class="paramname"><em>outs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>step</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Applique l'algorithme de retropropagation du gradient avec un jeu d'exemples afin d'entrainer le reseau. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ins</td><td>Tableau des exemples d'entrees du reseau </td></tr>
    <tr><td class="paramname">outs</td><td>Tableau des sorties attendues pour chaque exemple de ins (organises dans le meme ordre) </td></tr>
    <tr><td class="paramname">n</td><td>Nombre d'exemples </td></tr>
    <tr><td class="paramname">step</td><td>Pas d'apprentissage </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Rien </dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">tin</td><td>type des entrees (a priori double) </td></tr>
    <tr><td class="paramname">INPUT_SIZE</td><td>taille d'entree du reseau </td></tr>
    <tr><td class="paramname">tout</td><td>type des sorties du reseau (a priori double) </td></tr>
    <tr><td class="paramname">OUTPUT_SIZE</td><td>taille de sortie du reseau </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a781b53edd909baab32eb6f6d9a3921d6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a781b53edd909baab32eb6f6d9a3921d6">&#9670;&nbsp;</a></span>couch_size()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;std::size_t DEPTH&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::size_t <a class="el" href="classneuralnetwork_1_1_perceptron.html">neuralnetwork::Perceptron</a>&lt; DEPTH &gt;::couch_size </td>
          <td>(</td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>couch</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Nombre de neurones d'une couche donnee. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">couch</td><td>La couche en question </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Nombre de neurones de la couche en question </dd></dl>

</div>
</div>
<a id="a967eda62d33f3ac45cff0e6be3e6630a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a967eda62d33f3ac45cff0e6be3e6630a">&#9670;&nbsp;</a></span>depth()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;std::size_t DEPTH&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::size_t <a class="el" href="classneuralnetwork_1_1_perceptron.html">neuralnetwork::Perceptron</a>&lt; DEPTH &gt;::depth </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Profondeur du reseau. </p>
<dl class="section return"><dt>Returns</dt><dd>La profondeur du reseau sans prendre en compte la couche d'entree </dd></dl>

</div>
</div>
<a id="a83e9fbb5f68a8281fe29c51cc538e44c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a83e9fbb5f68a8281fe29c51cc538e44c">&#9670;&nbsp;</a></span>feedForward()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;std::size_t DEPTH&gt; </div>
<div class="memtemplate">
template&lt;typename tin , int INPUT_SIZE, typename tout , int OUTPUT_SIZE&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classneuralnetwork_1_1_perceptron.html">neuralnetwork::Perceptron</a>&lt; DEPTH &gt;::feedForward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; tin, INPUT_SIZE &gt; &amp;&#160;</td>
          <td class="paramname"><em>in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; tout, OUTPUT_SIZE &gt; &amp;&#160;</td>
          <td class="paramname"><em>out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>saveAgreg</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>saveActivation</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Evalue une entree avec le reseau. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">in</td><td>L'entree a evaluer </td></tr>
    <tr><td class="paramname">out</td><td>La sortie du reseau </td></tr>
    <tr><td class="paramname">saveAgreg</td><td>Si place a true, les agregations des differentes couches seront enregistrees </td></tr>
    <tr><td class="paramname">saveActivation</td><td>Si place a true, les activations des differentes couches seront enregistrees </td></tr>
  </table>
  </dd>
</dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">tin</td><td>type d'entree du reseau (a priori un double) </td></tr>
    <tr><td class="paramname">INPUT_SIZE</td><td>taille d'entree du reseau </td></tr>
    <tr><td class="paramname">tout</td><td>type des sorties du reseau (a priori un double) </td></tr>
    <tr><td class="paramname">OUTPUT_SIZE</td><td>taille de sortie du reseau </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a220623af970ea20a00bc2d9096946cbc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a220623af970ea20a00bc2d9096946cbc">&#9670;&nbsp;</a></span>initGraph()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;std::size_t DEPTH&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classneuralnetwork_1_1_perceptron.html">neuralnetwork::Perceptron</a>&lt; DEPTH &gt;::initGraph </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>step</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nb_threads</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Initailise les graphes TBB pour le feed forward et la retropropagation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">step</td><td>Pas d'apprentissage </td></tr>
    <tr><td class="paramname">nb_threads</td><td>En combien de lignes on decoupe chaque matrice et chaque transposee (meme nombre que les threads conseille) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Rien </dd></dl>

</div>
</div>
<a id="a82ed55bb881ead0fd7bb8b37a870fd98"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a82ed55bb881ead0fd7bb8b37a870fd98">&#9670;&nbsp;</a></span>initWeights()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;std::size_t DEPTH&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classneuralnetwork_1_1_perceptron.html">neuralnetwork::Perceptron</a>&lt; DEPTH &gt;::initWeights </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>min</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>max</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Initialisation aleatoire des poids du reseau entre deux bornes. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">min</td><td>Valeur minimal d'un poids du reseau </td></tr>
    <tr><td class="paramname">max</td><td>Valeur maximal d'un poids du reseau </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Rien </dd></dl>

</div>
</div>
<a id="a0f2a106043e5febb19e0d18a94e32dcc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0f2a106043e5febb19e0d18a94e32dcc">&#9670;&nbsp;</a></span>parallel_backpropagation()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;std::size_t DEPTH&gt; </div>
<div class="memtemplate">
template&lt;typename tin , int INPUT_SIZE, typename tout , int OUTPUT_SIZE&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classneuralnetwork_1_1_perceptron.html">neuralnetwork::Perceptron</a>&lt; DEPTH &gt;::parallel_backpropagation </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; tin, INPUT_SIZE &gt; *&#160;</td>
          <td class="paramname"><em>ins</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; tout, OUTPUT_SIZE &gt; *&#160;</td>
          <td class="paramname"><em>outs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>step</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Applique l'algorithme de retropropagation du gradient avec un jeu d'exemples afin d'entrainer le reseau avec TBB. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ins</td><td>Tableau des exemples d'entrees du reseau </td></tr>
    <tr><td class="paramname">outs</td><td>Tableau des sorties attendues pour chaque exemple de ins (organises dans le meme ordre) </td></tr>
    <tr><td class="paramname">n</td><td>Nombre d'exemples </td></tr>
    <tr><td class="paramname">step</td><td>Pas d'apprentissage </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Rien </dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">tin</td><td>type des entrees (a priori double) </td></tr>
    <tr><td class="paramname">INPUT_SIZE</td><td>taille d'entree du reseau </td></tr>
    <tr><td class="paramname">tout</td><td>type des sorties du reseau (a priori double) </td></tr>
    <tr><td class="paramname">OUTPUT_SIZE</td><td>taille de sortie du reseau </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a759d5647ad309215f083d5c8519838ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a759d5647ad309215f083d5c8519838ee">&#9670;&nbsp;</a></span>parallel_feedForward()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;std::size_t DEPTH&gt; </div>
<div class="memtemplate">
template&lt;typename tin , int INPUT_SIZE, typename tout , int OUTPUT_SIZE&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classneuralnetwork_1_1_perceptron.html">neuralnetwork::Perceptron</a>&lt; DEPTH &gt;::parallel_feedForward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; tin, INPUT_SIZE &gt; &amp;&#160;</td>
          <td class="paramname"><em>in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="_perceptron_8hpp.html#a1df3992453d71de615dab4ca5eadba8d">neuralnetwork::InOut</a>&lt; tout, OUTPUT_SIZE &gt; &amp;&#160;</td>
          <td class="paramname"><em>out</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Evalue une entree avec le reseau avec TBB. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">in</td><td>L'entree a evaluer </td></tr>
    <tr><td class="paramname">out</td><td>La sortie du reseau </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Rien </dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">tin</td><td>type d'entree du reseau (a priori un double) </td></tr>
    <tr><td class="paramname">INPUT_SIZE</td><td>taille d'entree du reseau </td></tr>
    <tr><td class="paramname">tout</td><td>type des sorties du reseau (a priori un double) </td></tr>
    <tr><td class="paramname">OUTPUT_SIZE</td><td>taille de sortie du reseau </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Rien </dd></dl>

</div>
</div>
<a id="ab05c12459b4ee03a75cc241b59aa0481"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab05c12459b4ee03a75cc241b59aa0481">&#9670;&nbsp;</a></span>printMatrixCouch()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;std::size_t DEPTH&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classneuralnetwork_1_1_perceptron.html">neuralnetwork::Perceptron</a>&lt; DEPTH &gt;::printMatrixCouch </td>
          <td>(</td>
          <td class="paramtype">std::ostream &amp;&#160;</td>
          <td class="paramname"><em>out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>i</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Ecrit la matrice des poids d'une couche, une ligne correspond a un neurone, les poids sont dans l'odre des entrees provenant de la couche precedente et les agregations et activations de cette couche (methode principalement utile au debugage) </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">out</td><td>reference sur le flux de sortie ou l'on veut afficher les informations </td></tr>
    <tr><td class="paramname">i</td><td>La couche en question </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Rien </dd></dl>

</div>
</div>
<a id="a6930cbdbb12382ffe13a5201d8ef47a8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6930cbdbb12382ffe13a5201d8ef47a8">&#9670;&nbsp;</a></span>weight()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;std::size_t DEPTH&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">double &amp; <a class="el" href="classneuralnetwork_1_1_perceptron.html">neuralnetwork::Perceptron</a>&lt; DEPTH &gt;::weight </td>
          <td>(</td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>couch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>neuron</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>previous</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Accesseur des poids du reseau. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">couch</td><td>La couche a laquelle appartient le neurone qui a le poids sur une de ses entrees </td></tr>
    <tr><td class="paramname">neuron</td><td>Le neurone de la couche </td></tr>
    <tr><td class="paramname">previous</td><td>Le neurone de la couche precedente </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Accesseur sur le poids </dd></dl>

</div>
</div>
<a id="a9e4e8b2536a300feb5050478bd54e0ab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9e4e8b2536a300feb5050478bd54e0ab">&#9670;&nbsp;</a></span>weights_count()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;std::size_t DEPTH&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::size_t <a class="el" href="classneuralnetwork_1_1_perceptron.html">neuralnetwork::Perceptron</a>&lt; DEPTH &gt;::weights_count </td>
          <td>(</td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>couch</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Nombre de poids de chaque neurone d'une couche. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">couch</td><td>La couche en question </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>le nombre de poids pour un neurone de la couche en question </dd></dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>src/<a class="el" href="_perceptron_8hpp_source.html">Perceptron.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
